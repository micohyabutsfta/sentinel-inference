FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git wget curl libstdc++6 libgomp1 libunwind8 \
    python3 python3-pip && \
    rm -rf /var/lib/apt/lists/*

# Install Python dependencies
RUN pip install fastapi uvicorn requests

# Install Llama.cpp
WORKDIR /workspace
RUN git clone https://github.com/ggerganov/llama.cpp.git && \
    cd llama.cpp && make

# Copy the fine-tuned model
COPY model.gguf /workspace/model.gguf

# Copy the FastAPI app
COPY main.py /workspace/main.py

# Start Llama.cpp and FastAPI
CMD cd /workspace && \
    ./llama.cpp/server -m model.gguf --host 0.0.0.0 --port 5000 --n-gpu-layers 35 --threads 8 & \
    uvicorn main:app --host 0.0.0.0 --port 8000
